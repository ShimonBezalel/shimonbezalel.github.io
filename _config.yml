title: DeepSOM: Deep Generative Manipulation for Naturalistic 3D Texture Synthesis
description: Deep generative models have become the state-of-the-art for 2D image related tasks such a manipulation, style-transfer, and novel image synthesis. Neural networks are capable of producing complex images with an organic aesthetic that appeal to creatives. In contrast, similar advancements in 3D object generation are being impeded, in part due to dataset limitations. We introduce Deep Single-Object Manipulation (DeepSOM), a novel 3D manipulation method with a convolutional backbone. We assume only a single input pair: the source object for manipulation and a primitive proxy. These are randomly augmented repeatedly using free-form deformation, forming the training dataset. Ultimately, changes made to the primitives are mapped to respective complex objects, so that even minor perturbations spawn highly variant shapes. This method is evaluated as a means of "freehand" synthesis of spatially textured surfaces, both in graphical renderings as well as potentially crafted objects.
